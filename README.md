# RNNs
An Experimental Study of Reccurent Neural Networks

This paper investigates the application of Recurrent Neural Networks (RNNs) in sentiment analysis, using the IMDB movie review dataset to evaluate various RNN architectures including basic RNNs, Long Short-Term Memory (LSTM), and Gated Recurrent Units (GRU). The research involves preprocessing with the Word2Vec technique for word embeddings, followed by experiments with different RNN configurations exploring various activation functions, and advanced LSTM and GRU models. Notably, the Tanh activation function outperforms others in baseline RNNs, challenging established norms. In-depth analysis shows that while LSTM excels in capturing complex patterns, GRU demonstrates greater computational efficiency. The study also explores the impact of bidirectionality in RNNs, assessing its influence on model performance across varying architectures. The findings confirm the effectiveness of RNNs, particularly LSTM and GRU, in sentiment analysis, underscoring their capability to handle complex sequential data and long-range dependencies.
